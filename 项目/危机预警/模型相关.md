

模型训练预测过程记录：  
1. 先通过 gsem_preprocess.ipynb 生成数据集，改 JOBID 和 suffix  
2. 准备好训练集，格式为 json 格式  
3. 在 CLUEdatasets 下创建名为 semeval_trainv10 的文件夹  
4. 把训练集复制到 semeval_trainv10，并命名为 train_trainv10_norm.json，并且创建软连接 `ln -s train_trainv10_norm.json train.json`  
5. 把验证集复制到 semeval_trainv10，并命名为 test_trainv10_norm.json，并且创建软连接  `ln -s test_trainv10_norm.json dev.json`  
6. vim run_classifier.py 注释 sent_num 相关代码，如果是预测，sent_num 的路径  
7. vim /home/crisis/mxnlp/run/23.gsem_v4/clue_classifier/processors/clue.py 修改 \_create_examples  
8. 训练 `./run_yuche2.sh train bert trainv10 norm semeval2_b128_r1_lr2e5 0 3 2e-5 1,1`  
9. 创建文件夹 `mkdir -p model/trainv10/bert`
10. 把训练好的模型复制到 model/trainv10/bert/ 下。路径从日志上打印的信息上复制 `cp semeval_trainv12_output/norm_semeval2_b128_r1_lr2e5/bert/checkpoint-17364/* model/trainv12/bert/`
11. 准备好测试集
12. 把测试集复制到 test 下，并重命名为 test.json `cp ../work/v10/testv17_norm.json test/test.json`  
13. 跑预测命令：`./run_predict2.sh bert model/trainv10/ test/`
14. 处理结果，结果在 clue_classifier/model/trainv10/bert/test_prediction.json  
15. 执行最后 eval_prediction.ipynb 最后几行  



v13 交叉验证：  
1. `./task_run.sh v13 v13_cv0 cv0`  
2. `./run_yuche2.sh train bert trainv13_cv0 norm semeval2_b128_r1_lr2e5 0 3 2e-5 1,1`
3. 复制 model：`cp semeval_trainv13_cv0_output/norm_semeval2_b128_r1_lr2e5/bert/checkpoint-3054/* model/trainv13_cv0/bert/`    

不再使用下面这种预测方式，而是只看验证集就可以了  
5. `cp test/testv17.json test/test.json`  
6. 预测：`./run_predict2.sh bert model/trainv13_cv0/ test/`  
7. `cp test/testv20.json test/test.json`  
8. 预测：`./run_predict2.sh bert model/trainv13_cv0/ test/`  


v14 交叉验证：  
1. `./task_run.sh v14 v14_cv0 cv0`  
2.  `./run_yuche2.sh train bert trainv14_cv0 norm semeval2_b128_r1_lr2e5 0 3 2e-5 1,1`


```python 
```

v6 是单句训练集，模型是 trainv6    
v7 是单句预测多句训练集  
v8 是处理成标准的 Excel 格式输出，即第一句有序号命中词，后面的句子没有；命中词和句子高亮  
v9 是加链接和评级  
v10 是用重新标注的 5000 条单句样本和从原始训练集中取 5000 条训练出来的模型；主要目的是查找单句训练集的标注错误    
v11 是用第二次重新标注的 2000 条数据，加上第一次重新标注的 5000 条数据训练的单句模型，是单句模型的基准模型。    
v12 是用 8 万条多句样本，加上第一次重新标注和第二次重新标注的样本，合并以后的数据，训练的多句模型。是后面 cross-validation 用的 base model   
v13 是多句交叉验证的模型  
v14 是单句交叉验证的模型  


```python 
```

## 文件  


### v5  
testv17_norm.json，7495 条，原来的 extract_abstract 函数提取的 sentence  
testv20_norm.json，1868 条，原来的 extract_abstract 函数提取的 sentence  


### v6  
testv17_norm.json，7988 条，sentence 是单句组成的列表的形式  
testv20_norm.json，1958 条，sentence 是单句组成的列表的形式  


### v8  
trainv8_norm.json，8 万条多句样本，有分句列表 sentence 字段，有没分之前的 long_sentence 字段  
ordered_trainv8_norm.json 和上面一样，8 万条多句样本，有分句列表 sentence 字段，有没分之前的 long_sentence 字段，而且是按照原始的顺序进行排序的    


### v9  
testv17_norm.json，7988 条，有单句列表和 long_sentence 字段  
testv20_norm.json，1958 条，有单句列表和 long_sentence 字段  


### v10  
模型反馈样本数据-标注后.xlsx，第一次重新标注的数据  
cd_relabel.json，5299 条，重新标注以后的 cd 数据，单句数据  



### v11
train_trainv11_norm.json，35511 条，单句数据，包括第一次和第二次重新标注以后的数据，和 v12 v14 中的 single_sentence.json 是同一个文件    
testv17_norm.json，7988 条，有单句列表和 long_sentence 字段  
testv20_norm.json，1958 条，有单句列表和 long_sentence 字段  
train_trainv11_norm_replaced_label.json，30212 条，单句数据，替换了第二次重新标注结果以后的结果  


### v12:  
trainv12_norm-Copy1.json，是 8 万条多句样本做 norm 以后的结果  
single_sentence.json，35511 条单句数据，包括第一次和第二次重新标注以后的数据，做了 normalize 以后的结果   
single_sentences_only_second_relabel.json，30212 条，单句数据，替换了第二次重新标注结果以后的结果  
trainv12_multi_sentence_with_replaced_cd_label.json，80246 条，多句样本替换 cd 第一次重新标注以后的结果。  
trainv12_norm.json，110458 条，多句样本替换 cd 第一次重新标注以后的结果，加上单句数据，替换了第二次重新标注结果以后的结果，是最后训练模型用的总数据  
train_trainv12_norm.json，88366 条，最后的训练集  
test_trainv12_norm.json，22092 条，最后的验证集  
testv17_norm.json，7495 条，原来的 extract_abstract 函数提取的 sentence  
testv20_norm.json，1868 条，原来的 extract_abstract 函数提取的 sentence  


### v13 
concate_all_cv.json，11366 条，合并的所有的 test_cv 文件，就是原始文件  


### v14 
single_sentence.json，35511 条单句数据，包括第一次和第二次重新标注以后的数据，做了 normalize 以后的结果   
危机预警系统数据12.17.xlsx，线上的业务数据  





v6 训练单句的时候的训练集是 train_trainv6_norm.json  

单句模型迭代用的是 trainv7，但是数据不是在 work/v7 下，训练数据是 work/v6 下的 train_trainv6_norm.json，这个 train_trainv6_norm.json 是原训练数据加了反馈数据的 c 类型和 d 类型的数据。  







### 模型部署  

虚拟环境是 server 环境  

cd model_serving  
改模型名，改文件夹名  
```shell 
1 torchserve --stop
2 torch-model-archiver --model-name gsemv4 --version 1.0 --serialized-file zfm_model/pytorch_model.bin --handler zfm_model/handler.py --extra-files "zfm_model/config.json,zfm_model/setup_config.json,zfm_model/index_to_name.json" && mv     *.mar ts_mar/
3 torchserve --start --model-store ts_mar --models gsemv4=gsemv4.mar --ncs --ts-config config.properties
```




#### 训练和预测的命令用 history 看  

训练模型命令：`nohup ./run_yuche2.sh train bert trainv3 norm semeval2_b128_r1_lr2e5 1 3 2e-5 1,1 &> logs/mxbert_20211107.log &`   


模型训练 GPU 命令：`./run_yuche2.sh train bert trainv3 norm semeval2_b128_r1_lr2e5 0 3 2e-5 1,1`  
`./run_yuche2.sh train bert trainv7 norm semeval2_b128_r1_lr2e5 0 3 2e-5 1,1`  



预测命令：`./run_predict2.sh bert model/norm_epoch_3(模型)/ test/`    





### 说明  

[在线文档](https://qrfmglwxn4.feishu.cn/docs/doccnhv1EpDdAcaYTv1F1Vbp1fc)  

是一种在线服务的形式  

SOC 正负面识别模型，用的是词性匹配  
    优点：快  
    缺点：业务不太匹配  
         准确度不够  

用的是历史标注数据，数据量在 1 万条左右，但是是整篇文章的标注，不是句子的标注，这个可以改进  

用的和科技搜搜的预测模型是一致的，不过只用了二分类模型，没有用提取模型  

运行中是根据关键词截取句子；一篇文章只有一个最后的结果。  

问题：  
主要就是速度问题  
1. 统计现在速度是多少 
2. 统计换成 bert 模型之后是多少  
3. 部署到 GPU 以后速度应该会提高不少 
4. SOC 的包可能还有问题  




