

模型训练预测过程记录：  
1. 先通过 gsem_preprocess.ipynb 生成数据集，改 JOBID 和 suffix  
2. 准备好训练集，格式为 json 格式  
3. 在 CLUEdatasets 下创建名为 semeval_trainv10 的文件夹  
4. 把训练集复制到 semeval_trainv10，并命名为 train_trainv10_norm.json，并且创建软连接 `ln -s train_trainv10_norm.json train.json`  
5. 把验证集复制到 semeval_trainv10，并命名为 test_trainv10_norm.json，并且创建软连接  `ln -s test_trainv10_norm.json dev.json`  
6. vim run_classifier.py 注释 sent_num 相关代码，如果是预测，sent_num 的路径  
7. vim /home/crisis/mxnlp/run/23.gsem_v4/clue_classifier/processors/clue.py 修改 \_create_examples  
8. 训练 `./run_yuche2.sh train bert trainv10 norm semeval2_b128_r1_lr2e5 0 3 2e-5 1,1`  
9. 创建文件夹 `mkdir -p model.trainv10/bert`
10. 把训练好的模型从 semeval_trainv10_output/norm_semeval2_b128_r1_lr2e5/bert/checkpoint-1932/ 复制到 model/trainv10/bert/ 下  
11. 准备好测试集
12. 把测试集复制到 test 下，并重命名为 test.json
13. 跑预测命令：`./run_predict2.sh bert model/trainv10/ test/`
14. 处理结果，结果在 clue_classifier/model/trainv10/bert/test_prediction.json  




```python 
```

v6 是单句训练集，模型是 trainv6    
v7 是单句预测多句训练集  
v8 是处理成标准的 Excel 格式输出，即第一句有序号命中词，后面的句子没有；命中词和句子高亮  
v9 是加链接和评级  
v10 是用重新标注的 5000 条单句样本和从原始训练集中取 5000 条训练出来的模型；主要目的是查找单句训练集的标注错误    
v11 是用第二次重新标注的 2000 条数据，加上第一次重新标注的 5000 条数据训练的模型  
v12 是用 8 万条多句样本，加上第一次重新标注和第二次重新标注的 35000 条单句样本，合并以后的数据，并且把单句和多句打乱顺序融合以后训练的模型  



```python 
```

## 文件  


### v8：  
trainv8_norm.json，8 万条多句样本，有分句列表 sentence 字段，有没分之前的 long_sentence 字段  
ordered_trainv8_norm.json 和上面一样，8 万条多句样本，有分句列表 sentence 字段，有没分之前的 long_sentence 字段，而且是按照原始的顺序进行排序的    


### v11
train_trainv11_norm.json，单句数据，包括第一次和第二次重新标注以后的数据  


### v12:  
trainv12_norm-Copy1.json 是 8 万条多句样本做 norm 以后的结果  
single_sentences.json 35511 条单句数据，包括第一次和第二次重新标注以后的数据，做了 normalize 以后的结果   
trainv12_norm.json 合并了 8 万条多句样本和 35511 条单句样本以后的结果，没有做 shuffle，所以前面是多句，后面是单句  
final_train_trainv12_norm.json 92605 条，上面的 shuffle 以后取的 80%，是最终的训练集  
final_dev_trainv12_norm.json 23152 条，上面的 shuffle 以后取的 20%，是最终的验证集  



v6 训练单句的时候的训练集是 train_trainv6_norm.json  

单句模型迭代用的是 trainv7，但是数据不是在 work/v7 下，训练数据是 work/v6 下的 train_trainv6_norm.json，这个 train_trainv6_norm.json 是原训练数据加了反馈数据的 c 类型和 d 类型的数据。  






#### 训练和预测的命令用 history 看  

训练模型命令：`nohup ./run_yuche2.sh train bert trainv3 norm semeval2_b128_r1_lr2e5 1 3 2e-5 1,1 &> logs/mxbert_20211107.log &`   


模型训练 GPU 命令：`./run_yuche2.sh train bert trainv3 norm semeval2_b128_r1_lr2e5 0 3 2e-5 1,1`  
`./run_yuche2.sh train bert trainv7 norm semeval2_b128_r1_lr2e5 0 3 2e-5 1,1`  



预测命令：`./run_predict2.sh bert model/norm_epoch_3(模型)/ test/`    





### 说明  

[在线文档](https://qrfmglwxn4.feishu.cn/docs/doccnhv1EpDdAcaYTv1F1Vbp1fc)  

是一种在线服务的形式  

SOC 正负面识别模型，用的是词性匹配  
    优点：快  
    缺点：业务不太匹配  
         准确度不够  

用的是历史标注数据，数据量在 1 万条左右，但是是整篇文章的标注，不是句子的标注，这个可以改进  

用的和科技搜搜的预测模型是一致的，不过只用了二分类模型，没有用提取模型  

运行中是根据关键词截取句子；一篇文章只有一个最后的结果。  

问题：  
主要就是速度问题  
1. 统计现在速度是多少 
2. 统计换成 bert 模型之后是多少  
3. 部署到 GPU 以后速度应该会提高不少 
4. SOC 的包可能还有问题  




