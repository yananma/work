

模型训练预测过程记录：  
1. 先通过 gsem_preprocess.ipynb 生成数据集，改 JOBID 和 suffix  
2. 准备好训练集，格式为 json 格式  
3. 在 CLUEdatasets 下创建名为 semeval_trainv10 的文件夹  
4. 把训练集复制到 semeval_trainv10，并命名为 train_trainv10_norm.json，并且创建软连接 `ln -s train_trainv10_norm.json train.json`  
5. vim run_classifier.py 注释 sent_num 相关代码  
6. vim /home/crisis/mxnlp/run/23.gsem_v4/clue_classifier/processors/clue.py 修改 \_create_examples  
7. 训练 `./run_yuche2.sh train bert trainv7 norm semeval2_b128_r1_lr2e5 0 3 2e-5 1,1`  
8. 把训练好的模型从 semeval_trainv10_output/norm_semeval2_b128_r1_lr2e5/bert/checkpoint-1932/ 复制到 model/trainv10/bert/ 下  
9. 准备好测试集  
10. 把测试集复制到 test 下，并重命名为 test.json  
11. 跑预测命令：`./run_predict2.sh bert model/trainv10/ test/`  
12. 处理结果，结果在 clue_classifier/model/trainv10/bert/test_prediction.json  
13. 










```python 
```

v6 是单句训练集，模型是 trainv6    
v7 是单句预测多句训练集  
v8 是处理成标准的 Excel 格式输出，即第一句有序号命中词，后面的句子没有；命中词和句子高亮  
v9 是加链接和评级  
v10 是用重新标注的 5000 条单句样本和从原始训练集中取 5000 条训练出来的模型；主要目的是查找单句训练集的标注错误    




v6 训练单句的时候的训练集是 train_trainv6_norm.json  

单句模型迭代用的是 trainv7，但是数据不是在 work/v7 下，训练数据是 work/v6 下的 train_trainv6_norm.json，这个 train_trainv6_norm.json 是原训练数据加了反馈数据的 c 类型和 d 类型的数据。  






#### 训练和预测的命令用 history 看  

训练模型命令：`nohup ./run_yuche2.sh train bert trainv3 norm semeval2_b128_r1_lr2e5 1 3 2e-5 1,1 &> logs/mxbert_20211107.log &`   


模型训练 GPU 命令：`./run_yuche2.sh train bert trainv3 norm semeval2_b128_r1_lr2e5 0 3 2e-5 1,1`  
`./run_yuche2.sh train bert trainv7 norm semeval2_b128_r1_lr2e5 0 3 2e-5 1,1`  



预测命令：`./run_predict2.sh bert model/norm_epoch_3(模型)/ test/`    





### 说明  

[在线文档](https://qrfmglwxn4.feishu.cn/docs/doccnhv1EpDdAcaYTv1F1Vbp1fc)  

是一种在线服务的形式  

SOC 正负面识别模型，用的是词性匹配  
    优点：快  
    缺点：业务不太匹配  
         准确度不够  

用的是历史标注数据，数据量在 1 万条左右，但是是整篇文章的标注，不是句子的标注，这个可以改进  

用的和科技搜搜的预测模型是一致的，不过只用了二分类模型，没有用提取模型  

运行中是根据关键词截取句子；一篇文章只有一个最后的结果。  

问题：  
主要就是速度问题  
1. 统计现在速度是多少 
2. 统计换成 bert 模型之后是多少  
3. 部署到 GPU 以后速度应该会提高不少 
4. SOC 的包可能还有问题  




