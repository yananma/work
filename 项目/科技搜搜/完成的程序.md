
08.11  

#### 调试 text_tools.py 代码  

```python 
from django.core.management import BaseCommand
from data_analysis.models import ZKYCountry
from data_analysis.tools.text_tools import TextFactory, reverse_keyfilter_result, add_tag_from_keyfilter_result

s = """文章内容"""

TEXT_COUNTRY_TAG = 'textcountry'


class Command(BaseCommand):
    def add_arguments(self, parser):
        parser.add_argument(
            '-i',
            dest='index',
            default='test-zky',
            help='插入到的ES的索引',
        )

    def handle(self, *args, **options):
        country_indexes = ZKYCountry.get_country_indexes()  # 国家AC自动机索引
        text_country_keyresults = reverse_keyfilter_result(country_indexes.exec_filter(s))

        result_s = add_tag_from_keyfilter_result(s, text_country_keyresults, TEXT_COUNTRY_TAG)

        var = TextFactory(result_s).chunk_tag_with_max_size_v2(tag_name=TEXT_COUNTRY_TAG).now
```


#### 从 ES 里查标题，这段代码可以直接拿来用，改查询字段、列表推导式查询字段、最后赋值的字段即可  

```python 
from collections import defaultdict
from typing import Tuple, List, Any

import pandas as pd

import yaml
import re
from django.conf import settings
from django.core.management import BaseCommand

from data_analysis.connect import ESConnect, ConnectManager
from data_analysis.piplines.es_craw_module import ESSpider

from pathlib import Path


class Command(BaseCommand):
    def add_arguments(self, parser):
        parser.add_argument(
            '-file',
            dest='file',
            default=settings.RESOURCE_ROOT / 'docs' / 'program' / 'ZKY_MAP_SETTING.yaml',
            help='配置的yaml文件',
        )
        parser.add_argument(
            '-si',
            dest='sindex',
            default='test-zky',
            help='查询的索引',
        )

    def handle(self, *args, **options):
        source_yaml = yaml.load(Path(options['file']).open('r', encoding='utf-8'), Loader=yaml.FullLoader)
        source_data = source_yaml.get('zky_temp_titles', None)

        print('程序开始运行......')
        query_dict = {
            "query": {
                "bool": {
                    "must": [
                        {
                            "bool": {
                                "should": [

                                ]
                            }
                        },
                        {
                            "range": {
                                "post_time": {
                                    "gte": "2021-05-04 00:00:00",
                                    "lt": "2021-08-05 00:00:00"
                                }
                            }
                        }
                    ]
                }
            },
        }
        for data in source_data:
            query_dict["query"]["bool"]['must'][0]['bool']['should'].extend([
                {"term": {
                    "title.keyword": {
                        "value": data
                    }
                }
                }
            ])
        result_text = []
        for data, next_search_after in ConnectManager.ES.get_setting('DEFAULT').search_by_page_with_searchafter(
                options['sindex'],
                doc=None,
                fields=['title', 'url', 'site_name', 'text'],
                query=query_dict,
                sort_fields=[{'post_time': 'desc'}, {'include_time': 'desc'}],
                return_sort=True
        ):
            print("开始查询......")
            result_text = [(it['title'], it['url'], it['site_name'], it['text']) for it in data]
            result_text.extend(result_text)
            print("查询结束......")
            break

        char_translate = str.maketrans({i: '' for i in
                                        r"""!"#$%｜&'()*+,-./:;<=>?@[\]^_`{|}~“”？，！～＠＃％＾＊【】（）、。：；’／
                                        ＼＿－＝☆★○●◎◇◆□€■△▲※→←↑↓¤♂♀〖〗『』」「‖〃‘……￥·"""})

        quchong_result = set()
        li = []
        for text in set(result_text):
            d = {}
            text0 = text[0].translate(char_translate)    # 标题去除特殊符号
            if text0 not in quchong_result:    # 功能去重
                quchong_result.add(text0)
            else:
                continue
            text0 = re.sub(r'(<.*?>)|(\n)', '', text[0])   # 展示标题去除特殊符号
            text3 = re.sub(r'(<.*?>)', '', text[3])  # 去掉标签和换行

            d["title"] = text0
            d['url'] = text[1]
            d['site_name'] = text[2]
            d['text'] = text3
            li.append(d)

        dataframe = pd.DataFrame(li)

        dataframe.to_csv(str(settings.RESOURCE_ROOT / 'docs' / 'program' / 'test.csv'), index=False, sep=',')

        print("写入完毕......")
```


08.10  

#### 首页最新收录舆情的日期过于久远 bug  

在 upload_hotposts_to_db.py  

查询条件有问题，去掉错误的查询条件就好了  


#### 去除标签  

用 html.unescape(s)  


#### 地区截取错误  

看截取规则  

country_posts_search_middleware.py 中的 trans_posts_to_web_format 函数  

问题：text_tools.py 中 now 是什么意思？有很多地方都有用到    

看到的就是文本  


chunk_tag_with_max_size_v2 函数分析    

```python 
  def chunk_tag_with_max_size_v2(self, tag_name, search_flag_str=None) -> "TextFactory":
      """
          根据要保留的高亮标签字段来自动截取合适的文本
      :param tag_name:
      :param search_flag_str:
      :return:
      """
      start_offset = self.now.find(search_flag_str or f'<{tag_name}') - 1    # search_flag_str 是 '<textcountry keyname="'，也就是说找到这个标签的位置
      prefix = '……'    # 最后截取段落的前缀
      endfix = '……'    # 最后截取段落的后缀
      str_max_len = len(self.now)    # 文章总长度
      temp_last_tag_offset = self.now.find(f'</{tag_name}>', start_offset)    # 从 start_offset 开始，找到闭合标签的位置  
      first_offset, last_offset = start_offset, temp_last_tag_offset + 3 + len(tag_name)    # 起始位置就是标签起始位置，结束位置是，标签名加两个括号加 / 符号
      if start_offset == 0:    # 如果最开始就是标签，就不加前缀
          prefix = ''
          
      # 创建标点符号表
      start_offset = self.stop_reverse_cpl.search(self.now, 0, start_offset)    # 前移了
      if start_offset is None:
          start_offset = 0
      else:
          start_offset = start_offset.end()   # 
      end_offset = self.stop_cpl.search(self.now, last_offset)    # 后移了，所以规则就是在正则表达式的匹配里  
      if end_offset is None:
          end_offset = str_max_len
          true_str = self.now[start_offset:end_offset] + '。'
      else:
          end_offset = end_offset.end()
          true_str = self.now[start_offset:end_offset]
          if true_str[-1] in ['\r', '\n']:
              true_str += '。'

      if start_offset in [0, 1]:
          prefix = ''
      if end_offset in [str_max_len]:
          endfix = ''
      return f'{prefix}{true_str}{endfix}'
```


08.06  

### 从 ES 里查两个词

```python 
import re
from django.conf import settings
from django.core.management import BaseCommand

from data_analysis.connect import ESConnect, ConnectManager
import pandas as pd


class Command(BaseCommand):
    def add_arguments(self, parser):
        parser.add_argument(
            '-si',
            dest='sindex',
            default='test-zky',
            help='查询的索引',
        )

    def handle(self, *args, **options):
        source_data = ["CEA-Leti", "拉曼研究所"]

        query_dict = {
            "query": {
                "bool": {
                    "should": [
                        {
                            "query_string": {
                                "fields": ["title", "text"],
                                "query":' OR '.join(f'"{data}"' for data in source_data)
                            }
                        }
                    ]
                }
            }
        }

        result = []
        for data, next_search_after in ConnectManager.ES.get_setting('DEFAULT').search_by_page_with_searchafter(
                options['sindex'],
                doc=None,
                fields=['title', 'url', 'post_time'],
                query=query_dict,
                sort_fields=[{'post_time': 'desc'}, {'include_time': 'desc'}],
                return_sort=True
        ):
            print("开始查询......")
            result_text = [(it['title'], it['url'], it['post_time']) for it in data]
            result.extend(result_text)
            print("查询结束......")
            break

        char_translate = str.maketrans({i: '' for i in
                                        r"""!"#$%｜&'()*+,-./:;<=>?@[\]^_`{|}~“”？，！～＠＃％＾＊【】（）、。：；’／
                                        ＼＿－＝☆★○●◎◇◆□€■△▲※→←↑↓¤♂♀〖〗『』」「‖〃‘……￥·"""})
        quchong_result = set()
        li = []
        for text in result:
            d = {}
            text0 = text[0].translate(char_translate)
            if text0 not in quchong_result:
                quchong_result.add(text0)
            else:
                continue
            text0 = re.sub(r'(<.*?>)|(\n)', '', text[0])
            d["title"] = text0
            d['url'] = text[1]
            d['post_time'] = text[2]
            li.append(d)

        data_frame = pd.DataFrame(li)

        data_frame.to_csv(str(settings.RESOURCE_ROOT / 'docs' / 'program' / 'test1.csv'), index=False, sep=',')

        print("完成......")
```


### 从 ES 里查标题  

```python
from collections import defaultdict
import pandas as pd

import yaml
import re
from django.conf import settings
from django.core.management import BaseCommand

from data_analysis.connect import ESConnect, ConnectManager
from data_analysis.piplines.es_craw_module import ESSpider

from pathlib import Path


class Command(BaseCommand):
    def add_arguments(self, parser):
        parser.add_argument(
            '-file',
            dest='file',
            default=settings.RESOURCE_ROOT / 'docs' / 'program' / 'ZKY_MAP_SETTING.yaml',
            help='配置的yaml文件',
        )
        parser.add_argument(
            '-si',
            dest='sindex',
            default='test-zky',
            help='查询的索引',
        )

    def handle(self, *args, **options):
        client: ESConnect = ConnectManager.ES.get_setting('DEBUG')
        source_yaml = yaml.load(Path(options['file']).open('r', encoding='utf-8'), Loader=yaml.FullLoader)
        source_data = source_yaml.get('zky_temp_titles', None)

        print('开始......')
        query_dict = {
            "query": {
                "bool": {
                    "must": [
                        {
                            "bool": {
                                "should": [

                                ]
                            }
                        },
                        {
                            "range": {
                                "post_time": {
                                    "gte": "2021-05-04 00:00:00",
                                    "lt": "2021-08-05 00:00:00"
                                }
                            }
                        }
                    ]
                }
            },
        }
        for data in source_data:
            query_dict["query"]["bool"]['must'][0]['bool']['should'].extend([
                {"term": {
                    "title.keyword": {
                        "value": data
                    }
                }
                }
            ])

        for data, next_search_after in ConnectManager.ES.get_setting('DEFAULT').search_by_page_with_searchafter(
                options['sindex'],
                doc=None,
                fields=['title', 'text', 'url'],
                query=query_dict,
                sort_fields=[{'post_time': 'desc'}, {'include_time': 'desc'}],
                return_sort=True
        ):
            print("开始查询......")
            result_text = [(it['title'], it['text'], it['url']) for it in data]
            print("查询结束......")
            break


        char_translate = str.maketrans({i: '' for i in
                                        r"""!"#$%｜&'()*+,-./:;<=>?@[\]^_`{|}~“”？，！～＠＃％＾＊【】（）、。：；’／
                                        ＼＿－＝☆★○●◎◇◆□€■△▲※→←↑↓¤♂♀〖〗『』」「‖〃‘……￥·"""})
        
        from collections import Counter
        keywords_counter = Counter()
        quchong_result = set()
        l = []
        for text in set(result_text):
            d = {}
            text0 = text[0].translate(char_translate)
            if text0 not in quchong_result:
                quchong_result.add(text0)
            else:
                continue
            text0 = re.sub(r'(<.*?>)|(\n)', '', text[0])
            text1 = re.sub(r'(<.*?>)', '', text[1])  # 去掉标签和换行

            keywords = []
            for word in source_word:
                if word in text0 + text1:
                    keywords.append(word)
            d["title"] = text[0]
            d['keywords'] = keywords
            d['url'] = text[2]
            l.append(d)
            keywords_counter.update(keywords)
        print()

        dataframe = pd.DataFrame(l)

        dataframe.to_csv(str(settings.RESOURCE_ROOT/'docs'/'program'/'test.csv'), index=False, sep=',')

        print("写入完毕......")
```


### 把数据写入到数据库里  

```python 
import logging
from django.core.management.base import BaseCommand
import pandas as pd
from django.conf import settings

from data_analysis.models import ZKYCountry

logger = logging.getLogger('mxlog')


class Command(BaseCommand):
    def add_arguments(self, parser):
        parser.add_argument(
            '-file',
            dest='file',
            default=settings.RESOURCE_ROOT / 'docs' / 'program' / 'country_rule V3.xlsx',
            help='配置的yaml文件',
        )

    def handle(self, *args, **options):
        # ZKYCountry.objects.all().delete()
        df: pd.DataFrame = pd.read_excel(options['file'].__str__())
        for d in df.iterrows():
            ZKYCountry.objects.update_or_create(
                name=d[1]["name"],
                defaults={
                    'synonyms': d[1]["synonyms"] if d[1]["synonyms"]==d[1]["synonyms"] else '',
                    'limiter': d[1]["limiter"] if d[1]["limiter"]==d[1]["limiter"] else '',
                    'exclude_limiter': d[1]["exclude_limiter"] if d[1]["exclude_limiter"]==d[1]["exclude_limiter"] else '',
                    'level': d[1]['level'] if d[1]["level"]==d[1]["level"] else '',
                }
            )
            logger.info(f'完成')
```


