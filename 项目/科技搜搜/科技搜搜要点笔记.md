
#### 单点突破  

重点资讯 important_search_middleware.py 中的 es 函数里，flag 代表是监管部门，还是中央媒体。  

CACHE_DEBUG 的重点是 debug，如果为 True，就代表正在进行 debug，不要使用 cache，一般就是设置成 False。  

如果 CACHE_DEBUG 为 False，那么在 cache_worker.py 中的 settings.CACHE_DEBUG 也是 False，这样的话就会去 Redis 里真的查缓存存在不存在。  

如果 CACHE_DEBUG 为 True，那么在 cache_worker.py 中的 settings.CACHE_DEBUG 也是 True，这样就会走 if，这样就会一直返回 False，这样只要调用 exists 方法就会返回 False，这样就相当于没有缓存。  


#### 环境配置  

1、测试环境  

测试环境的配置在 settings_test.py 中。  

数据库是：192.168.241.51  
ES 索引：kejisousou-test  
Redis 缓存：192.168.241.20，数据在 4 库里  


2、正式环境  

正式环境的配置在 settings.py 中  

数据库是：192.168.241.23  
ES 索引：test-zky  
Redis 缓存：192.168.241.20，数据在 7 库里  



### 项目总体介绍  

#### connect 包

各种连接方式、ES 还多一个分页方法，这个方法比较重要，用的比较多。  

kafka 有一个生产和消费，send 生产，receive 是消费。get_consumer 指定消费者  

MySQL 就一个连接  


#### filters 包

全是匹配部分  

base.py 传一组规则，传入规则名，同义词、限定词、反向限定词，主要是查国家用的。高级搜索里使用。key_rules 用于匹配，可以同时匹配多条规则。  

add_key 一组规则，add_keys 多组规则。exec_filter 是查询用的，传入规则  

reverse_keyfilter_result()，把结果转换了一种返回形式。    

esm 传很多关键词，匹配一句话就能把命中的关键词和位置筛出来，在 index 的 AutoIndex 类中。  


#### tools 包

各种工具  

mx_simhash.py 不看  

text_tools.py 扩展的文本处理，有各种各样的处理方法，可以链式调用（返回了 self）（有很大的改进空间）  

threadingadapter.py 多线程，多进程，返回结果队列传个 piplines 中使用    

utils.py 延迟加载，不重要  


#### piplines 包

normalize_data 格式化数据  

process_data 处理数据  


接收数据、处理数据、返回数据，异步运行（多线程，多进程）  

linemodule.py last_step_queue 接收 threadingadapter.py 中处理完成的数据，主要有 3 个方法，read_data 读数据，normalize_data 预处理，process_data 是正规处理数据。  

db_read_module.py 从数据库批量读数据，返回数据  

es_bulk_module.py 批量操作 ES，主要是增删改    

es_craw_module.py 主要是从 ES 中查数据   

forecast_module.py 筛选包好预测关键词的文章，去除不在的  

lac_module.py 提取人名、机构、关键词，专家观点。给产品进行规则分析用的。  

origin_post_module.py 没用，不看  

output_module.py 转换成 Excel 格式。不用看  

zhili_module.py  选取有治理关键词的文章  



#### user 应用

下 utils.py trans_to_md5 把所有传入的内容转换成 md5，有一个生成验证码的函数，不用管。  

views.py   


#### post 应用  

前端展示的，几乎所有方法都有缓存功能，可以指定过期时间，因为数据要每天更新，所以可以指定时间过期  

ZKYCache 类，操控 Redis，缓存是用 Redis 实现的  

get_by_args 函数，根据传的参数取 name  

HotPostsView 就是 5 篇文章，每天更新，先尝试获取缓存，  

important_search 是重点资讯  



### 数据  

数据库 zky_posts 是中科院的数据表  

upload_to_community 项目，从 kafka 上传数据到 ES  

upload_to_community 文件夹下的 upload.py，上传数据用的，不是查    

normalize_else 是上传到中科院  


XSite 是所有的有效的域名，取到域名以后，会和这个数据库比对，取到有效的域名  

entry 是当前，site 父域名   


