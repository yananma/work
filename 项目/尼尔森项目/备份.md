
```python 
    max_group_sentences = []
    for group in groups:    # groups 是所有的分组，group 是同一个位置的所有的文字
        # 差异性最大的是字幕
        if len(set(group['sentences'])) > len(set(max_group_sentences)):
            group["is_zimu"] = True
            max_group_sentences = group['sentences']
        else:
            group["is_zimu"] = False

    update_is_zimu(groups)

    # 最后再做一次过滤
    if len(set(max_group_sentences)) <= 5:
        max_group_sentences = []

    all_zimu_sentences = ','.join(max_group_sentences)
    txt.write(all_zimu_sentences)
    txt.close()
```


```python 
def main(video_name):
    frame_dir = settings.VIDEO_FRAME_DIR + video_name.split('.')[0] + '/'
    output_dir = settings.OUTPUT_DIR + video_name.split('.')[0] + '/'
    if not (os.path.exists(output_dir)):
        os.mkdir(output_dir)
    ocr = PaddleOCR(use_angle_cls=True, lang="ch", use_gpu=False)
    run_time = datetime.datetime.now().strftime("%Y_%m_%d_%H_%M_%S")
    txt = open(output_dir + str(run_time) + '.txt', 'a', encoding='utf-8')
    frames = sorted(filter(is_img, os.listdir(frame_dir)))

    groups = grouping_by_position(frames, frame_dir, ocr)

    max_group_sentences = []
    for group in groups:    # groups 是所有的分组，group 是同一个位置的所有的文字
        # 差异性最大的是字幕
        if len(set(group['sentences'])) > len(set(max_group_sentences)):
            group["is_zimu"] = True
            max_group_sentences = group['sentences']
        else:
            group["is_zimu"] = False

    update_is_zimu(groups)

    # 最后再做一次过滤
    if len(set(max_group_sentences)) <= 5:
        max_group_sentences = []

    all_zimu_sentences = ','.join(max_group_sentences)
    txt.write(all_zimu_sentences)
    txt.close()
    get_zimu_position(groups)
    print('finish.')
``` 

```python
def get_ocr_result(frame_dir, img, ocr):
    """一次传入一张图片，OCR 识别这张图片的所有文字，返回结果为[{},{}]格式"""
    image = frame_dir + img
    result = ocr.ocr(image, cls=True)  # OCR 识别。
    print(result)
    ret_result = []
    # line[1][0], line[1][1], line[0]  # 文字   置信度    位置
    for line in result:
        left_upper_y = line[0][0][1]
        left_bottom_y = line[0][3][1]
        ret_result.append({
            'sentence': line[1][0],
            'txt_position': line[0],
            'top': left_upper_y,
            'height': left_bottom_y - left_upper_y
        })
    return ret_result
```  

ocr.py main()  

```python 
   output_dir = settings.OUTPUT_DIR + video_name.split('.')[0] + '/'
   if not (os.path.exists(output_dir)):
       os.mkdir(output_dir)
```

ocr.py grouping_by_position()  
```python 
                # Avoid duplicate: check if current word is similar to last word
                if len(group['sentences']) >= 3:
                    for last_word in group['sentences'][-3:]:
                        if difflib.SequenceMatcher(None, last_word, sentence).quick_ratio() > 0.8:
                            duplicate_flag = True
                            break
                else:
                    last_word = group['sentences'][len(group['sentences']) - 1]
                    if difflib.SequenceMatcher(None, last_word, sentence).quick_ratio() > 0.8:
                        break
                if duplicate_flag:
                    break
```

ocr.py   
```python 
def separate_zimu_huazi(ocr_result, zimu_top, zimu_height):
    """分离字幕和花字，遍历每一句的识别结果，和字幕位置作比较"""
    zimu_list = []
    huazi_list = []
    if zimu_top is None and zimu_height is None:  # 如果没有字幕，则全部文字都是花字
        for line in ocr_result:
            if line['sentence'] not in huazi_list:
                huazi_list.append(line['sentence'])
        return zimu_list, huazi_list
    for line in ocr_result:
        if abs(line["top"] - zimu_top) <= 3 * zimu_height and abs(line["height"] - zimu_height) < 0.15 * zimu_height:
            zimu_list.append(line['sentence'])
        else:
            huazi_list.append(line['sentence'])
    return zimu_list, huazi_list
``` 

ocr.py  
```python 
def separate_zimu_huazi(ocr_result, zimu_top, zimu_height):
    """分离字幕和花字，遍历每一句的识别结果，和字幕位置作比较"""
    zimu_list = []
    huazi_list = []
    if zimu_top is None and zimu_height is None:  # 如果没有字幕，则全部文字都是花字
        for line in ocr_result:
            if line['sentence'] not in huazi_list:
                huazi_list.append(line['sentence'])
        return zimu_list, huazi_list
    for line in ocr_result:
        duplicate_flag = False
        if abs(line["top"] - zimu_top) <= 3 * zimu_height and abs(line["height"] - zimu_height) < 0.15 * zimu_height:
            if len(zimu_list) >= 3:
                for last_word in zimu_list[-3:]:
                    if difflib.SequenceMatcher(None, last_word, line['sentence']).quick_ratio() > 0.8:
                        duplicate_flag = True
                        continue
            else:
                for last_word in zimu_list:
                    if difflib.SequenceMatcher(None, last_word, line['sentence']).quick_ratio() > 0.8:
                        duplicate_flag = True
                        continue
            if duplicate_flag:
                continue
            zimu_list.append(line['sentence'])
        else:
            if len(huazi_list) >= 3:
                for last_word in huazi_list[-3:]:
                    if difflib.SequenceMatcher(None, last_word, line['sentence']).quick_ratio() > 0.8:
                        duplicate_flag = True
                        continue
            else:
                for last_word in huazi_list:
                    if difflib.SequenceMatcher(None, last_word, line['sentence']).quick_ratio() > 0.8:
                        duplicate_flag = True
                        continue
            if duplicate_flag:
                continue
            huazi_list.append(line['sentence'])
    return zimu_list, huazi_list
```

ocr.py  严格去重，效果更好  
```python 
def separate_zimu_huazi(ocr_result, zimu_top, zimu_height):
    """分离字幕和花字，遍历每一句的识别结果，和字幕位置作比较"""
    zimu_list = []
    huazi_list = []
    if zimu_top is None and zimu_height is None:  # 如果没有字幕，则全部文字都是花字
        for line in ocr_result:
            if line['sentence'] not in huazi_list:
                huazi_list.append(line['sentence'])
        return zimu_list, huazi_list
    for line in ocr_result:
        if abs(line["top"] - zimu_top) <= 3 * zimu_height and abs(line["height"] - zimu_height) < 0.15 * zimu_height:
            if line['sentence'] not in zimu_list:
                zimu_list.append(line['sentence'])
        else:
            if line['sentence'] not in huazi_list:
                huazi_list.append(line['sentence'])
    return zimu_list, huazi_list
``` 

大改前备份    
```python 
# -*- coding:utf-8 -*-
import difflib
import importlib
import json
import sys

import pandas as pd

import settings

importlib.reload(sys)
pd.set_option('display.max_rows', None)
pd.set_option('max_colwidth', 800)


def get_ocr_result(df):
    """读取 CSV 文件，返回整个 video 的 OCR 识别结果"""
    df = df.sort_values(by=[0, 3], key=lambda x: x if x.name == 0 else x.map(lambda x: json.loads(x)[0][1]))  # 排序，先按图片名排，同一张图片中按文字从上往下排
    ret_result = []
    for row in df.iterrows():
        position = json.loads(row[1][3])
        left_upper_y = position[0][1]
        left_bottom_y = position[3][1]
        ret_result.append({
            'sentence': row[1][2],
            'txt_position': position,
            'top': left_upper_y,
            'height': left_bottom_y - left_upper_y
        })
    return ret_result  # 返回结果为 [{},{},{}...] 格式，字典中为每一句的文本和位置


def update_is_zimu(groups):
    """
    修正 is_zimu 字段。
    因为之前的判断，一个 video 里可能会有好几个 is_zimu 为 True 的 group。这里修正以后，只有真正的字幕的 is_group 为 True
    """
    find_zimu = False
    for group in reversed(groups):
        if find_zimu == False and group["is_zimu"] == True:
            find_zimu = True
        else:
            group["is_zimu"] = False


def add_is_zimu(groups):
    """给字幕分组添加 is_zimu 字段"""
    max_sent_list = []
    for group in groups:  # groups 是所有的分组，group 是同一个位置的所有的文字
        # 差异性最大的是字幕
        if len(set(group['sentences'])) > len(set(max_sent_list)):
            group["is_zimu"] = True
            max_sent_list = group['sentences']
        else:
            group["is_zimu"] = False
    update_is_zimu(groups)
    # 最后再做一次过滤
    if len(set(max_sent_list)) <= 4:
        max_sent_list = []
    return max_sent_list


def get_zimu_position(groups):
    """获取字幕的位置，也就是字幕的 top 和 height"""
    max_group_sentences = add_is_zimu(groups)
    if not max_group_sentences:  # 如果 max_group_sentences 为空，也就是最大组去重以后句子个数小于等于 5 个的，就判定为没有字幕，即全部都是花字
        for group in groups:
            print(group)
        return None, None
    for group in groups:
        if group["is_zimu"]:
            print()
            print(group)
            # return group["top"], group["height"]
        else:
            print()
            print(group)
    for group in groups:
        if group["is_zimu"]:
            return group["top"], group["height"]


def grouping_by_position(df):
    """按位置分组，是整个程序的核心"""
    groups = []
    ocr_result = get_ocr_result(df)
    # print(ocr_result)
    for line in ocr_result:  # ocr_result 是同一张图片的所有文字的识别结果
        top = int(line['top'])
        height = int(line['height'])
        sentence = line['sentence']
        exist = False
        for group in groups:
            duplicate_flag = False
            # 遍历已有识别结果，如果新的结果的 top 值与 group 的 top 之差小于区域高度的 2/3，而且高度之差不超过原有 height 的 15%，则认为是一组的
            if abs(group['top'] - top) < (group['height'] / 3 * 2) and abs(group["height"] - height) < 0.15 * group["height"]:
                exist = True  # 这个位置的分组已经存在
                # Avoid duplicate: check if current word is similar to last word
                if len(group['sentences']) >= 3:
                    for last_word in group['sentences'][-3:]:
                        if difflib.SequenceMatcher(None, last_word, sentence).quick_ratio() > 0.8:
                            duplicate_flag = True
                            break
                else:
                    for last_word in group['sentences']:
                        if difflib.SequenceMatcher(None, last_word, sentence).quick_ratio() > 0.8:
                            duplicate_flag = True
                            break
                if duplicate_flag:
                    break
                group['sentences'].append(sentence)
                # update group position
                group['total_top'] += top
                group['total_height'] += height
                group['total_num'] += 1
                group['top'] = int(group['total_top'] / group['total_num'])
                group['height'] = int(group['total_height'] / group['total_num'])
                break

        if not exist:  # 如果这个位置的分组不存在，就创建这个位置的分组
            groups.append({
                'top': top,  # group standard, using average value of tops
                'total_top': top,
                'height': height,
                'total_height': height,
                'total_num': 1,  # how many pics has been add to this group
                'sentences': [sentence]
            })
    return groups, ocr_result


def separate_zimu_huazi(ocr_result, zimu_top, zimu_height):
    """分离字幕和花字，遍历每一句的识别结果，和字幕位置作比较"""
    zimu_list = []
    huazi_list = []
    if zimu_top is None and zimu_height is None:  # 如果没有字幕，则全部文字都是花字
        for line in ocr_result:
            if line['sentence'] not in huazi_list:
                huazi_list.append(line['sentence'])
        return zimu_list, huazi_list
    for line in ocr_result:
        duplicate_flag = False
        if abs(line["top"] - zimu_top) <= 3 * zimu_height and abs(line["height"] - zimu_height) <= 0.25 * zimu_height:
            # if line['sentence'] not in zimu_list:
            #     zimu_list.append(line['sentence'])
            if len(zimu_list) >= 3:
                for last_word in zimu_list[-3:]:
                    if difflib.SequenceMatcher(None, last_word, line['sentence']).quick_ratio() > 0.8:
                        duplicate_flag = True
                        continue
            else:
                for last_word in zimu_list:
                    if difflib.SequenceMatcher(None, last_word, line['sentence']).quick_ratio() > 0.8:
                        duplicate_flag = True
                        continue
            if duplicate_flag:
                continue
            zimu_list.append(line['sentence'])
        else:
            if line['sentence'] not in huazi_list:
                huazi_list.append(line['sentence'])
    return zimu_list, huazi_list


def main(video_name):
    df = pd.read_csv(settings.CSV_DIR + video_name.split(".")[0] + '.csv', header=None)
    groups, ocr_result = grouping_by_position(df)
    zimu_top, zimu_height = get_zimu_position(groups)
    zimu_list, huazi_list = separate_zimu_huazi(ocr_result, zimu_top, zimu_height)
    print()
    print('字幕')
    print(",".join(zimu_list))
    print()
    print('花字')
    print(",".join(huazi_list))
    print('finish.')
``` 


