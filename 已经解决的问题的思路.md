
# 写到 10000 行就差不多了   

*** 

# 过拟合和交叉验证   

1. 读课程，听课程，听 20 遍   
2. 读《动手学深度学习》
3. 读《统计学习方法》
4. 第《机器学习》
5. 读《深度学习入门》  
6. 读《Keras》
1. 过拟合非常重要。训练模型，很多时间都是用在了解决过拟合问题上。   
2. 什么是过拟合  
3. 为什么会有过拟合（算损失）
4. 奥卡姆剃刀
5. 决策树
6. 信息熵，信息增益
7. 剪枝  
8. 线性回归
9. 正则化，L2 范数    
10. 什么是 R 方分数    
11. 为什么要有验证集。
12. 什么是交叉验证。
13. 随机森林。   
14. 解决过拟合的方法。500 问。  


# 列表页搜索 04.13   

1. 确定搜索范围。ocr、logo、品种。已完成。      
2. 写视图函数。已完成。  
3. 写查询条件，搜索字段内容。已完成。
4. 获取 video_id。已完成。   
5. 写 HTML，添加搜索 button id，修改 CSS 样式。已完成。  
6. jQuery 获取输入框内容。已完成。   
7. debug 视图函数，走通最开始的流程。已完成。   
8. 修改模型文件，添加外键约束。已完成。   
9. 解决字段名 clashes 问题。已完成。
10. 修改字段名，解决报错问题。已完成。   
11. 测试在 models 里添加数据库没有的字段能不能进行查询。不行，必须要用已有的字段。已完成。
12. 删除远程环境。已完成。
13. 重新配置远程环境。已完成。
14. 本地安装 Django。已完成。   
15. 读 Django 文档，找外键查询的方法。已完成。   
16. 学习 ForeignKey。已完成。   
17. 外键查询。已完成。   
18. 删除 PyCharm 远程环境配置。已完成。
19. 删除远程和本地文件夹。已完成。  
20. git clone 远程和本地文件夹。已完成。   
21. 重新配置 PyCharm 远程连接。已完成。   
22. 卸载原来的环境。已完成。  
23. 重新安装新的环境。已完成。
24. 重新配置远程连接。已完成。   
25. 复制 Django。已完成。   
26. 学习 Linux 的 zip 和 unzip 命令。已完成。   
27. 修改 models 字段，添加外键。已完成。  
28. 跨关联关系查询。已完成。   
29. 查询结果按 video_id 去重。已完成。   
30. 查询结果按上传时间倒序排列。已完成。
31. 解决排序不生效问题。已完成。
32. 优化 NielsenItem 模型和 NielsenUpload 关系。添加外键。已完成。      
33. 上传 gitlib。已完成。   


# 详细页搜索 04.12  

1. 确定搜索范围。ocr、logo、品种。已完成。   
2. 看科技搜搜是怎么实现搜索的。已完成。   
3. 看 django 官方文档，看数据库多字段搜索。已完成。   
4. 写视图函数。已完成。   
5. 写 url 路由。已完成。     
6. 写 jQuery 函数。已完成。
7. 获取搜索框内容。已完成。
8. 怎么调用 get_detail_data 函数。已完成。
9. 怎么区分是搜索还是普通访问。已完成。
10. 看海上装备代码。已完成。
11. 删除搜索的视图函数和 url 路由。因为搜索和展示用的是同一个视图函数。已完成。           
12. 先用最简单的方法解决查询问题。先走通流程。已完成。
13. 解决查询结果布局错位问题。img_area.empty()。已完成。
14. 上传 gitlib。已完成。


# 列表页点击进入详情页 04.12    

1. 参考原来的跳转办法。window.location.href。已完成。
2. 先实现最简单的跳转。已完成。  
3. 绑定 video_id。已完成。   
4. 怎么携带参数。已完成。   
5. 参考原来的代码，绑定 onclick 函数。已完成。
6. 修改视图函数，接收 vid 参数。已完成。  
7. 修改 url，添加 id。已完成。
8. 两个视图，两个 url 都要添加 vid。已完成。    
9. jQuery 获取 id。已完成。
10. jQuery 发送 Ajax 请求。已完成。   
11. 原来的请求方式，找静态文件的时候会有问题，更改请求方式。已完成。
12. 使用 localStorage 存取 video_id。已完成。
13. 测试效果。已完成。       


# 替换列表页内容 04.11  

1. 写视图函数。已完成。
2. 查 filter in 方法。已完成。
3. 写 jQuery 文件的 Ajax 请求。已完成。   
4. 测试流程有没有走通。已完成。    
5. 写测试。已完成。
6. 先试试展示一个视频。已完成。
7. 看 img 的 src 是怎么找的。已完成。
8. jQuery 遍历返回的结果。已完成。    
9. 拆解 video 函数。已完成。   
10. 替换 video。已完成。  
11. 替换 title。已完成。    
12. 每一行加竖直滚动条。已完成。
13. 修改 a 链接字号。已完成。  
14. 加完成状态过滤。已完成。   


# 替换详细页右侧内容 04.10    

1. 动态替换品种。已完成。  
2. 动态替换字幕。已完成。    
3. 动态替换花字。已完成。   
4. 解耦 HTML。已完成。    
5. 图片排序。已完成。


# 动态替换改为 jQuery 形式 04.08  

1. 缩略图页面继承 base.html。已完成。
2. git 备份。已完成。   
3. 删除 Django 语法。已完成。
4. 复制内容到 js 文件。已完成。   
5. 查 jQuery 中 Ajax 用法。已完成。    
6. 读 Ajax 用法。已完成。
7. 复制 Ajax 内容到 js 文件。已完成。
8. 看 url。detail。已完成。
9. 看原来项目返回的数据的类型。已完成。   
10. 怎么找到 html。已完成。
11. 先实现展示功能。已完成。


# 优化尼尔森字幕花字提取 04.06  

1. 优化代码。已完成。   
2. 增加 set 相似度去重。已完成。   
3. 遍历 set 以后的结果，再按 75% 去重。已完成。     
4. 找 difflib 去重的代码。已完成。    


# 详情页面动态替换 04.03     

1. 看数据库，重新跑 inspectdb。已完成。    
2. 添加 for 循环。已完成。   
3. 重构静态文件，添加 base.html，解决详情页面访问静态文件路径错误问题。
4. 替换图片。已完成。   
5. 静态文件路径。已完成。
6. 动态配置路径。已完成。   


# 集成静态文件，后端前期配置 04.01   

1. 实现 Django 集成静态文件。已完成。        
2. 更改左上角链接。已完成。  
3. 修改 favicon.ico。已完成。
4. 配置数据库。已完成。   
5. inspectdb。已完成。      


# 标注检查工具详细页静态页面 03.30   

1. 复制 HTML，复制 CSS。已完成。   
2. 调整箭头大小。已完成。
3. 改箭头背景颜色。已完成。     
4. 改箭头和按钮左右间距。已完成。   
5. 更改竖直间距。已完成。
6. 展开箭头布局。已完成。  
7. 展开 button 布局。已完成。   
8. input 展示内容。已完成。   
9. input 的 border 不显示。已完成。   
10. 设置 input 的 border 样式。已完成。   
11. input 指定长度。已完成。    
12. 多行样式。已完成。
13. input 换行。已完成。   
14. input 对齐。已完成。   
15. 添加 delete icon。已完成。
16. 字幕 button 设置。已完成。    
17. arrow 样式。已完成。   
18. arrow 同一行。已完成。         
19. css 写到 css 文件里。已完成。       


# 海上装备适配问题 03.26  

1. 看 bootstrap 栅格文档。已完成。
2. 改浏览器大小。已完成。      
3. 停掉服务器后台。已完成。   
4. pycharm 起服务。已完成。    
5. 先改一个页面。已完成。   
6. 改所有页面。已完成。      


# 标注检查工具列表页静态页面 03.25     

1. 顶部背景颜色。已完成。   
2. 左上角下拉框。已完成。   
3. 左上角下拉框背景颜色。已完成。
4. 搜索框，搜索 icon 融合到按钮里。已完成。
5. 筛选下拉框，布局。已完成。   
6. 筛选下拉框，定位，宽度。已完成。   
7. 右侧每页显示多少条。已完成。   
8. 视频区域定位。已完成。   
9. 展示视频封面。已完成。  
10. 展示视频 title。已完成。   
11. 右侧按钮区域布局。已完成。   
12. 右侧 label 和 button 布局。已完成。   
13. button 对齐；背景颜色；扁平化；内部文字线宽、颜色。已完成。      
14. label 对齐。已完成。   
15. 页码。已完成。   
16. select 选中后有黑框。已完成。   


# 专家观点库搜索速度慢 03.22  

1. 怎么查两个索引。已完成。   
2. 怎么开多线程。已完成。   
3. 怎么判断哪一个先返回。已完成。
4. 怎么杀线程。已完成。     


# 创建一个新索引，只存姓名全称 03.19     

1. 创建索引模板。已完成。   
2. 从原始数据里取数据。已完成。   
3. 上传到新索引。已完成。       
4. 新索引是怎么按月份分索引的。已完成。      
5. 把跑数据脚本存成一个标准的存取数据的代码，以后参考。已完成。      
6. 定时任务。已完成。      


# 运行标注检查工具源码 03.16   

1. 找服务器。b62。已完成。
2. 创建虚拟环境。已完成。   
3. 安装包。已完成。  
4. 测试网站是否可以运行。已完成。 
5. git clone 源码。已完成。   
6. 运行源码。已完成。  
7. 创建 sqlite 数据库。已完成。   
8. 删除环境重装。已完成。       
9. 配置 PyCharm。已完成。   
10. 下载文件。已完成。   


# 找标注工具开源项目 03.16 

未完成，最后是彭老师找到的。寻找方法不对。应该找能用的，仔细看。结果是走马观花，忘记了自己可以修改。   

看百度标注网站的源码   

功能：web 工具；修改标注结果，添加、删除、修改；一屏多张图片；可以指定打开路径，可以指定保存路径。

查看方法：看动图，看 UI，看功能、看 readme 标题、看 readme   

1. CVAT，web 工具，docker 安装，没有找到缩略图显示功能；没有找到编辑标注框的功能      
2. COCO Annotator，web 工具，docker 安装，没有安装，看着挺好            
3. VoTT，archived 
4. EVA，web 工具，没有安装，看着挺简陋，安装要求还特别多   
5. LOST web 工具，docker 安装，看着不错    
6. Ybat，好安装，但是非常简陋，功能太少   


# 海上装备从原来数据库导出数据到现在数据库里 03.15

1. 创建一个新的 .py 文件。已完成。   
2. 看原来代码。已完成。  
3. 找到表对应的模型。已完成。    
4. 看表之间的关系。已完成。   
5. 复制模型。已完成。     
6. 确定模型代码放在哪里。要不要和本来就有的模型放在一起。看是不是有重名的模型。新建一个模型文件。已完成。    
7. 看字段含义。已完成。   
8. 看需要哪些字段。看之前的命令。已完成。
9. 数据库配置。看原来的代码。已完成。   
10. 官方文档看 Django 多数据库配置。已完成。
11. 去官方文档查 using 的用法。已完成。   
12. 开始写命令。已完成。
13. 解决导包问题，看之前的代码是怎么导包的。已完成。
14. 类改名字。已完成。
15. 从数据库查询，再 print，走通取数据流程。已完成。   
16. 先处理一条。已完成。     
17. 复制之前的命令。已完成。
18. 查原来是怎么从 task 找到 paper 的。已完成。   
19. 再遍历所有。已完成。
20. 解决 posts 累加问题。已完成。   
21. 判断 public_year 为空。已完成。  


# 优化专家观点库搜索速度 03.15   

先用 filter 优化搜索   
1. 看网上文章里的例子。已完成。  
2. 在 kibana 试。已完成。   
3. 看科技搜搜。已完成。   
4. 改代码为 filter。已完成。  
5. 验证效果。已完成。
6. 做笔记。已完成。


# 上科院项目上传文件 03.14      

关键是理解代码的意思，弄明白原来文件的格式       

要 debug 原来的代码   

1. 下载 Excel 文件。已完成。    
2. 创建 .py 文件。已完成。
3. 上传 Excel 文件到服务器。已完成。   
4. 复制代码。已完成。
5. 解决导包问题。已完成。   
6. 看用到了哪些字段，看 request。已完成。   
7. 创建用户。已完成。   
8. 先读三遍原来的代码。已完成。
9. debug 原来的视图函数。已完成。  
10. 重构代码。已完成。
11. 先读一个文件。已完成。   
12. 替换字段。已完成。
13. 写成 command。已完成。     
14. 替换 user 实例。已完成。   
15. 重构代码。已完成。
16. 解决文章覆盖问题。已完成。    
17. 替换 nan 为空。已完成。   
18. 上传数据。已完成。      



# 标签转换 03.08    

总体原则：  
不干扰原来的代码。  
写一个转换命令。  
voc 转换结果存在一个新文件夹里，自己通过复制实现展示。    

1. 转换什么时候的数据。最最后的结果，有 is_zimu 字段。已完成。
2. 新建一个 .py 文件，专门处理标签转换。已完成。
3. 在 run.py 中调用新文件的接口。已完成。    
4. 保存为 txt 文件，一张图片是一个 txt。已完成。
5. 看猫狗识别的文件。看看是什么样式。已完成。
6. 弄明白猫狗识别的 txt 标注文件中坐标的含义。txt 中的坐标的含义是：xmin、ymin、width、height。已完成。
7. 看文档里命令的路径。已完成。
8. 会不会影响已有的 CSV？是不是要新建一个文件夹。需要新存一个 txt 文件夹。已完成。
9. 两个 OCR 识别结果不一致的问题。解决办法是要到 CSV 文件，自己这里跑字幕花字分离，自己这边处理。已完成。    
10. 同一张图片的多行字幕怎么拼接。已完成。
11. 转换成什么格式。VOC 格式。已完成。
12. 找到之前的代码。已完成。
13. 坐标转换。怎么简单怎么来。取图片高度。已完成。
14. 把转换的命令代码写成一个 .py 文件。已完成。
15. 写转换 VOC 的代码，要注意的事情是只取有字幕的文件，也就是先遍历 txt 文件夹，然后再根据文件名取 img。已完成。
16. 转换结果存到什么地方。应该和图片放在同一个文件夹下面，然后要写一个删除的参数，实现删除的功能。已完成。
17. 放在同一个文件夹下，会不会影响读取图片。实现删除图片文件下所有 .xml 功能。已完成。
18. 在 run.py 中实现 if 判断，不要每次都注释。已完成。
19. 这个版本上传到自己的 gitlab 上，新建一个项目 extract_subtitles2。已完成。    


# Redis 存搜的词，可以按时间删除 03.08  

1. 怎么存。时间为键，词为值。时间精确到秒。已完成。    
2. 第一天存了，第二天又存，怎么弄。不影响。已完成。
3. 怎么创建出字典。已完成。
4. Redis 怎么存数据，怎么存字典。redis.set()
5. 怎么取。redis.get()   
6. 取出来怎么判断。已完成。   
7. 怎么判断一天前。已完成。
8. 时间大小怎么比较。已完成。
9. 怎么删，遍历删。已完成。   
10. 怎么删除 1 天前的搜索记录。已完成。   


# 专家观点库设置定时任务 03.07   

怎么设置定时任务，看科技搜搜代码        
1. gitlab 看科技搜搜跑数据定时任务。已完成。  
2. gitlab 看科技搜搜跑数据代码。已完成。
3. 改专家观点库代码。已完成。
4. Linux 怎么设置定时任务，看 PDF。已完成。
5. 设置命令。 


# 机器学习课程 03.03  

1. 整理飞书笔记。已完成。   
2. 什么是机器学习，能干什么。已完成。       
3. 模型。训练和预测。已完成。
4. 什么是权重。已完成。    
5. 什么是分类问题，什么是回归问题。已完成。
6. 回归是什么意思。已完成。
7. 什么是梯度。就当做斜率就可以。已完成。 
8. 梯度下降。百度，吴恩达。已完成。   
9. 求导公式。百度。已完成。
10. 《d2l》。已完成。


# 字幕重构，去重优化 03.01  
改成类。已完成。  
CSV 第一列改格式。已完成。   
时间和帧数不是完全对应的，还要看切帧的频率。已完成。  

最后处理结果，按帧前后去重，去重规则：  
1. 如果当前帧的 time 大于等于 3 秒，就遍历前面 3 秒的帧。已完成。     
2. 如果当前帧的 time 小于 3 秒，就遍历前面所有的帧。已完成。       
3. 持续出现的，解决重复的问题。已完成。   

结论：   
大体上字幕是可读的。主要是改成了类，然后就可以实现按帧去重，之前是取列表后 3 个，有问题上下取 3 行。    
1. 花字，也就是背景字，有非常多重复的。50 多个视频，字数多 3 万多字，每个视频多 600 字，主要是包装袋。而且慢了很多。if 当前 not in，就 append 到 huazi_list   
2. 字幕，换了按时间去重以后，50 多个视频，字数减少 600 多字，每个视频减少 10 几个字，因为按帧去重更彻底。  
3. 不能用 not in，因为看了几个，确实是说话会有重复的。比如一款猫粮，然后说配方前三位是。下一款又说配方前 3 位是。比如有一个连续拍了 5 天的视频，每一个最开始都说 哈喽，我叫什么。    
4. 最突出的是几个问题：跳动字幕还是没有办法。现在没办法，后面做成工具也是没办法。
5. 背景包装袋，字的大小差不多。没有办法区分前景背景，彦彬最后是去知网看论文了，看了。
6. 字幕下面有稳定的字，会有重复的问题。比如包装袋，最多的问题。比如聊天记录，比如标题。可以解决。 
7. 漏字不是一个严重的问题。我看了十几个，我看到的是漏了三四句。重复的问题更严重一些。   
8. 怎么做测试呢？怎么知道效果好了呢？我现在的办法就是读，凭感受。   

看 10 个视频视频，验证效果。已完成。   


# GPU 准备工作 02.26  

把 opencv 的视频过一遍。已完成。  
GPU 部署。已完成。  
跑视频。已完成。     
连 pycharm。已完成。    
conda -c 参数含义。已完成。    
添加 try_except。已完成。   
log 添加 文件名。已完成。  
log 日志，第几帧。已完成。   


# 跑抖音视频，看效果 02.24

1. 取前 100 个视频。已完成。  
2. 放在什么文件夹下。已完成。  
3. 传到本地。已完成。  
4. 保存中间识别过程。就是 CSV 文件。已完成。  
5. 展示最后结果。已完成。  
6. 看哪里有问题。已完成。  


# 字幕花字提取优化 02.22   

1. debug 重复问题。已完成。
2. 去重的效果，在一组里是很好的，但是在整体里，效果不好。因为会离得很远，比如小红书，还有上下多句的问题。好处是，可能凑不够 5 条，就全部都是花字。不如之前效果好。
3. 识别结果按 y 轴排序。已完成。
4. 最开始分组的时候加了高度限制，效果大幅提升。
5. 多次测试，找到合适的高度限制。

1. 字幕和花字的消重问题。之所以会有这个消重问题，是因为切帧，会有相同的图片。一个位置就是一个组，这里面是只有高度，没有宽度的限制。只比较最后一个，就消除不掉。做了判断。
2. 排序问题。之前不是个问题，是因为按帧往下走的。有一个排序，是按照文件名排的。但是对于同一张图片里的文字，是乱的，之前看不出来，但是现在多行字幕，就会有这个需求。所以最后就是，先按图片名排，同一张图片里再按 y 轴坐标，从上往下排。


# 把 notebook 转换成脚本 02.17  

1. add_argument 怎么写？参考 zjgdk。已完成。  
2. 文件夹版本。已完成。    
3. 获取路径最后的文件名。已完成。    
4. 获取文件名的去除后缀的名称。已完成。    
5. 名称按 _ split，取索引为 0 的真正的名称。已完成。    
6. 输入的路径参数，不管带不带斜杠，都要能够正常运行。已完成。     
7. label 判断，是猫狗的时候才替换。已完成。  
8. 没有参数报错提示。已完成。  
9. 单元测试。已完成。  
10. 文档。已完成。  


# annotation 格式转换 02.14 

1. 现有的标注样式  
2. VOC 格式的标准样式  
3. 读 github 上 labelImg 转 VOC 的代码  
4. 先转换一个文件  
5. 转换所有文件  


# 首页表格显示 02.11  

1. 查哪个表。mx_task_info 表  
2. 对应的是哪个模型。TaskInfo 模型    
3. 上传成功是什么状态，没有上传成功是什么状态。上传成功是 6，没有上传成功是 7      
4. 写视图函数
5. Ajax 请求 
6. 在什么时候请求  
7. 在哪里写请求  


# 多次上传文件 02.10   

1. 读完 jQuery 代码，复制出来有用的东西。         
2. 获取已经有的文件。  
3. 把文件添加到列表。  
4. 取消现在 input 的 label  
5. 添加新的 label     
6. 获取上传文件的文件名    
7. 最后上传的是列表中所有的文件。 
8. 在点击取消和新建以后，重置列表      
9. 多个文件上传以后，鼠标悬停的信息的展示。tooltips    


# 热词项目核心功能 01.30 

1. 搭建环境。已完成。    
2. 读取 Excel，判断空行。已完成。   
3. 判断第一行，提取人名。已完成。     
4. 取非人名文本。已完成。  
5. 分词。已完成。    
6. stopwords。已完成。  
7. 统计词频。已完成。    
8. 按词频排序。已完成。  
9. 人名次数统计。做一个字典映射，把这个人说过的话的分词结果都放到值中，拿到排序结果以后，遍历统计，得到每个词对应的用户，最后取用户的个数。已完成。      
10. 自己配置词性功能。已完成。  
11. 人次组合到元组里。已完成。    
12. 优化整合代码；已完成。
13. 写视图函数。已完成。


# 单句模型交叉验证 01.23  

1. 找到网址。ifconfig 找到网址。已完成。  
2. notebook 的 token。vim /home/crisis/logs/notebook.log，复制日志的 token。已完成。  
3. 找到原始的单句数据集。single_sentence.json。已完成。    
4. 找到新的样本数据。v13/危机预警系统数据12.17.xlsx。已完成。  
5. 从新数据中找到所有的单句。已完成。  
6. 合并数据集。这一步不用做，直接用最新的模型做 fine-tune 就好了。  
7. 用逗号隔开 keyword。已完成。  
8. 训练一个单句模型。已完成。  
9. 训练多个单句模型。已完成。  
10. 修改代码，适应单句模型 predict。已完成。  
11. 完成交叉验证。已完成。    



# 海上装备后台用户页面 01.20 

1. 先做提示：如果为空，就提示请输入。已完成。  
2. 复制提示信息样式到 HTML 文件中。已完成。  
3. 解决确认密码不提示问题。已完成。  
4. 输入框变化，提示信息隐藏。已完成。     
5. 实现密码验证功能。已完成。  
6. 再次点击，清空输入框。已完成。  
7. 修改密码弹框，再次点击，清空输入框。已完成。    
8. 下拉框对应数字。已完成。  
9. 弄明白上传文件和修改权限的下拉框处理逻辑。已完成。    
10. 用户展示接口。已完成。
11. 写后端接口。已完成。  
12. 遍历结果。已完成。    
13. 添加用户接口。已完成。  
14. 添加用户完成以后，清空输入框。已完成。  
15. 用户表格滚动条。已完成。    
16. 删除用户接口。已完成。  
17. 先删除一条，跑通接口。已完成。    
18. 根据 CheckBox 勾选，修改提示信息，先实现一条。已完成。 
19. 实现提示信息，提示多个用户。已完成。
20. 完成用户名之间的顿号的处理。已完成。    
21. 根据 CheckBox 勾选，删除勾选的这一条。已完成。    
22. 根据 CheckBox 勾选，删除勾选的多条。已完成。    
23. 刚进入网页的时候，删除用户按钮为 disabled。已完成。  
24. 如果没有勾选，删除用户按钮为 disabled；勾选以后为可点击状态。已完成。 
25. 删除用户以后，删除用户按钮为 disabled。已完成。  
26. 实现登录。已完成。  
27. 看 login 视图函数。已完成。
28. 请求 login 接口。已完成。
29. 拿到 token。已完成。
30. 把 token 添加到 headers 里。已完成。
31. 看后端哪里用到了 token。已完成。
32. token 怎么设置成全局变量。（用 localStorage）已完成。  
33. 怎么获取当前用户属性。已完成。  
34. 修改密码接口。已完成。  
35. 完善修改密码接口。已完成。  
36. 先走通修改密码接口。已完成。  
37. 根据用户，实现密码修改。已完成。  
38. 看权限接口代码。已完成。  
39. 走通数据库。已完成。
40. 弄懂 type 是什么，怎么传。已完成。  
41. 走通 permission list 接口。已完成。
42. 根据当前用户的权限，判断左侧哪些内容显示，哪些内容隐藏。已完成。  
43. 通过 jQuery 实现左侧显示？  
44. 实现管理员和研究人员登录按钮。已完成。    
45. 根据用户，在右上角显示不同的用户名。通过视图函数实现。已完成。  
46. 弄清楚链接跳转的流程。已完成。
47. 弄清楚 cookie 和 localStorage 的作用。已完成。  
48. 完成跳转。已完成。  



# 热词统计 01.13  
1. 读 Excel。已完成。  
2. 两列，去空白符。已完成。  
3. 逗号分词。已完成。  
4. 正则匹配。已完成。  
5. 统计词频。已完成。  
6. 循环 update。已完成。  
7. 同义词相加。已完成。  
8. 取最高值。已完成。  



# 专家观点库姓名识别基本功能 01.06  

1. 去治理索引找一篇文章，有人名，有全称。已完成。  
3. 动词匹配。用正则表达式，findall 和 finditer。已完成。  
4. 判断有没有分段。str.find("\n") 或 re.findall("\n") 或者 re.finditer("\n")。已完成。  
5. 如果分段，就在一个段落里找，如果没有分段，就在一句话里找。怎么判断一句话。已完成。  
6. 往前找和往后找。已完成。  
7. 跑词性。已完成。  
8. 找全称的正则。已完成。 
9. 找 PER。已完成。   
10. 把结果合成一个列表。已完成。  
11. 列表排序。已完成。  
12. 实现 name_map。已完成。  
13. 根据姓名相对于动词的位置，进行排序。已完成。    
14. 根据 type，判断是否返回。已完成。  


# 训练模型 01.03    

一、先训练多句模型  
1. 看交叉验证  
2. 准备训练集  
3. 训练模型  
4. 交叉验证  



1. 复制代码。已完成。 
2. 读代码，看用到了哪些函数。已完成。 
3. 把用到的函数复制过去。已完成。  
4. 看调用函数有什么修改。已完成。  
5. 准备训练集。已完成。  
6. 执行一下过程，看看报什么错，进行相应的调整，看看生成的数据的格式  
7. 写 shell 脚本  
8. 完成 predict  


# 重新训练一版多句模型  12.26 

1. 先删除训练的模型。已完成。  
2. 找到 c 和 d 数据。已完成。  
3. 处理第二次标注的 c 和 d 类型的数据，先分组  
4. 根据规则合并 
5. 准备多句模型数据  
6. 多句模型数据标签替换  
7. 合并单句数据  



# 海上装备后台 12.15  

1. 先布局。已完成。  
2. 先创建出一个空页面出来。已完成。    
3. 添加表格。已完成。    
4. 添加管理员三角形。已完成。  
5. 实现弹框。已完成。    
6. 复制粘贴，创建多个页面。已完成。  



# 用第二次标注数据迭代模型 12.11  

1. 上传第二次标注数据。已完成  
2. 找到原始 3 万条单句样本。已完成。train_trainv6_norm.json  
3. 把原始单句样本中的第二次标注的数据的标签，替换为重新标注的标签。已完成。  
4. 合并单句样本和第一次标注的 5000 条样本。已完成。合并以后的数据为 work/v11/train_trainv11_norm.json   
5. 训练模型。已完成。  
6. 找到测试集。已完成。    
7. 测试效果。已完成。  


# 第 2 个单句模型 12.09 

1. 找到重新标注的 5000 条。已完成。是 work/v10/cd_relabel.json  
2. 找到单句样本。已完成。是 clue_classifier/CLUEdatasets/semeval_trainv6/train_trainv6_norm.json  
3. 取第 2 个 5000 条。已完成。  
4. 合并 json 文件，生成训练集。已完成。  
5. 训练模型。已完成。   
6. 准备好测试集。已完成。work/v10/train_trainv6_norm_first_5000.json    
7. 预测结果。已完成。    
8. 用 cleanlab 统计错例。已完成。  



# 单句训练 12.09   

1. 找到标注以后的数据。已完成。在 work/v10/模型反馈样本数据-标注后.xlsx    
2. 转换成 JSON 文件。已完成。重新标注以后的数据在 work/v10/cd_relabel.json  
3. 用标注以后的数据训练一个模型。已完成。
4. 用这个模型在单句样本上测试效果。已完成。  



# 迭代单句模型 12.01 

测试结果  

准备测试数据：  
1. 找到原始数据 290000 样本。已完成。是 work/v8/final_trainv8_norm_290000.json    
2. 找到 c 和 d 类型的数据。已完成。是 work/v8/c_label0_some_preds1.json 和 work/v8/d_label1_all_preds0.json  
3. 把 c 和 d 从原始数据中去除。已完成。  
4. 在去掉 c 和 d 后剩下的数据中随机采样，取一半。已完成。  
5. 找到训练集。已完成。  
6. 在 c 和 d 中去掉重新标注的训练集。已完成。    
7. 把 c 和 d 中剩下的数据拼接到随机采样一半的结果里。已完成。测试集是：half_sample_test_set_with_cd.json    
8. 先用原来的模型在测试集上测试效果  
9. 再用迭代的模型在测试集上测试效果  



# 添加 url、原来的评级和模型预测标签 11.26  

1. 先做预测标签，查生成的 Excel，复制、替换。已完成。  
2. url 和原来的评级一起做，读原始数据，处理成字典格式进行遍历。


# 文本转为 Excel 格式 11.21  

1. 取 10 条做实验。复制粘贴就可以。已完成。  
2. 写入 Excel。已完成。  
3. 写入多个 sheet。已完成。  
4. 写入 Excel 按句子 split。已完成。  
5. 颜色高亮。已完成。    


# 测 LAC 分词速度 11.17   

## 方法 1 

1. 读 CSV 文件  
2. 过 LAC  
3. 打标签  


# 皮卡专家观点提取 11.17    

## 方法 1 

1. 先从 es 取数据  
2. 用动词过滤  
3. 用正则过滤  
4. title 去重  


# 单句模型处理测试集 11.16  

## 方法 1   

`label_map = {1: "负面", 0: "正面"}`  

1. 怎么遍历多句
2. 怎么把句子送进模型
3. 怎么决定输出


## 方法 2 

1. 遍历多句 
2. 返回句子个数列表  
3. 跑模型，得到中间每个句子的结果
4. 根据结果分组，根据分组得到最后的结果


# 具体内容错例分析 11.11 

## 方法 1 

错例和句子个数的相关性  

1. 把正确的例子从验证集中分出来。已完成。  
2. 统计错例句子长度各自占比。 
3. 统计正确句子长度各自占比  
4. 比较结果  


# 错例分析 11.10   

## 方法 1 

1. predict 验证集  
2. 拿到 test_prediction.json  
3. 把 test_prediction 标签和验证集标签做对比，直接用 zip 就可以    
4. 不相等的拿出来  
5. 分析  



# ES 改 flag 脚本 11.09 

## 方法 1  

1. 先取数据
2. 拿到 flag 字段 
3. 做判断  
4. update 字段  


# 国家统计和国家文章列表缓存没有生效  11.04 

## 方法 1   

1. 看 Redis 里有没有缓存  
2. 看代码中是在哪里取的缓存  
3. 有没有取到缓存？为什么  

先确认国家统计是不是每次请求。已完成，是每次都重新请求。    

确认国家统计有没有生效。缓存没有生效。    

然后看文章列表。没有问题。    


# 训练 en v3 模型 11.03  

换数据执行命令应该就行了  

1. 先删除原来的模型。已完成。  
2. 换数据。已完成。    
3. 改标签。已完成。  
4. 训练新的模型。已完成。
5. 模型部署。已完成。  
6. 跑数据。已完成。    

改脚本，说清楚原来的问题，怎么改  

走通原来的代码  
说清楚原来的问题  
给出解决方案  


# 字幕和花字分离 11.01   

## 方法 4   

有两个问题：  
1. 字幕顺序被打乱了；先确定是不是乱了，对比视频和文字。已完成，确定顺序是乱的；乱了怎么排序；用 pandas 的 sort_values()    
2. 按照高度限制。1、高度是多少？2、限制写在哪里？3、怎么设置为空  


## 方法 3 

两条路  

1、读代码，理解思想 
2、再找别的项目  


## 方法 2   

先读 readme 文档。已完成。    

走通流程  

debug 5 遍代码  


## 方法 1  

### 问题  

识别的字不一样  
重复率取多少？文本长短，比如一共 10 句话，一句字幕就占了 10%。可能还要做判断。  
怎么根据位置判断。（每个视频字幕位置不一样）  


### 流程  

2. 定规则  
① 不管技术，定规则  
字幕相对固定，出现在特定区域，并且持续出现，内容变化度高  
花字重复率高，每帧识别结果重复度高  

② 考虑技术
先判断重复率，重复率非常高的是花字  
再判断位置，位置相对固定的，内容变化度高的是字幕  

7. 根据位置和变化率进行判断  


### 已完成  

1. 读聊天记录，读文档，读 CSV 文件，读脚本。完成   

2. 读取 CSV 文本。已完成。  

3. 统计数量。已完成。

4. 算重复率。已完成。  

5. 提取位置  
坐标含义：已完成。  


# 预测治理统计匹配的每一步都是多少数据 10.26  

## 方法 1  

先做预测，先做中文    


### 分析过程  

1. 姓名匹配以后剩多少？姓名匹配是在哪里做的。  
先看视图函数和 middleware，先看预测  
4. 正则怎么匹配  


# 技术预测和技术治理的提取 09.07   

先做技术治理。  

原来是在全文里找，现在要在一段里找。  

1、原来是怎么找的。  
2、这一段是怎么找的。  
3、把全文改成一段就可以了。  

有一个问题是，现在的技术预测里的 point_text 有些是全文。这个最后做。  



不是看预测和治理，而是看专家观点。  


技术治理原来显示的内容是怎么找的。  

原来是直接用的 zhili_text，在 es 里就是有 zhili_text。  

es 索引是 zhili-zky，有 zhili_text 这个字段，看这个字段是怎么上传到 es 中去的  

找不到。  



看一看预测原来显示的内容是怎么找的。  


08.23  

# 只显示 10 页，10 页以后的内容没有办法显示

问题产生的原因：最开始返回的总页数是，从 ES 里查的总数，但是使用缓存的时候就改成了单批缓存的数量。  

解决办法：使用缓存的时候，不要使用单批缓存的数量，而是使用总数量的缓存。  


# 判断是使用缓存，还是再次请求

最开始是想使用页数，想在缓存名前加页数，一直不成功，点击 15 页，没有文章显示，而且会报错，说是无效的请求。  

这个问题的核心是判断当前数量是在缓存范围内，还是缓存范围之外；如果是在缓存范围之内，就使用缓存，如果在缓存范围之外，就再次去 ES 里查询

解决办法：用数量做判断。如果在数量以内，就使用缓存，如果在数量以外，就再次取 ES 里查询。    



