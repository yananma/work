

# 多次上传文件 02.10   

1. 读完 jQuery 代码，复制出来有用的东西。         
2. 获取已经有的文件。  
3. 把文件添加到列表。  
4. 取消现在 input 的 label  
5. 添加新的 label     
6. 获取上传文件的文件名    
7. 最后上传的是列表中所有的文件。 
8. 在点击取消和新建以后，重置列表      
9. 多个文件上传以后，鼠标悬停的信息的展示。tooltips    


## 热词项目核心功能 01.30 

1. 搭建环境。已完成。    
2. 读取 Excel，判断空行。已完成。   
3. 判断第一行，提取人名。已完成。     
4. 取非人名文本。已完成。  
5. 分词。已完成。    
6. stopwords。已完成。  
7. 统计词频。已完成。    
8. 按词频排序。已完成。  
9. 人名次数统计。做一个字典映射，把这个人说过的话的分词结果都放到值中，拿到排序结果以后，遍历统计，得到每个词对应的用户，最后取用户的个数。已完成。      
10. 自己配置词性功能。已完成。  
11. 人次组合到元组里。已完成。    
12. 优化整合代码；已完成。
13. 写视图函数。已完成。


# 单句模型交叉验证 01.23  

1. 找到网址。ifconfig 找到网址。已完成。  
2. notebook 的 token。vim /home/crisis/logs/notebook.log，复制日志的 token。已完成。  
3. 找到原始的单句数据集。single_sentence.json。已完成。    
4. 找到新的样本数据。v13/危机预警系统数据12.17.xlsx。已完成。  
5. 从新数据中找到所有的单句。已完成。  
6. 合并数据集。这一步不用做，直接用最新的模型做 fine-tune 就好了。  
7. 用逗号隔开 keyword。已完成。  
8. 训练一个单句模型。已完成。  
9. 训练多个单句模型。已完成。  
10. 修改代码，适应单句模型 predict。已完成。  
11. 完成交叉验证。已完成。    



# 海上装备后台用户页面 01.20 

1. 先做提示：如果为空，就提示请输入。已完成。  
2. 复制提示信息样式到 HTML 文件中。已完成。  
3. 解决确认密码不提示问题。已完成。  
4. 输入框变化，提示信息隐藏。已完成。     
5. 实现密码验证功能。已完成。  
6. 再次点击，清空输入框。已完成。  
7. 修改密码弹框，再次点击，清空输入框。已完成。    
8. 下拉框对应数字。已完成。  
9. 弄明白上传文件和修改权限的下拉框处理逻辑。已完成。    
10. 用户展示接口。已完成。
11. 写后端接口。已完成。  
12. 遍历结果。已完成。    
13. 添加用户接口。已完成。  
14. 添加用户完成以后，清空输入框。已完成。  
15. 用户表格滚动条。已完成。    
16. 删除用户接口。已完成。  
17. 先删除一条，跑通接口。已完成。    
18. 根据 CheckBox 勾选，修改提示信息，先实现一条。已完成。 
19. 实现提示信息，提示多个用户。已完成。
20. 完成用户名之间的顿号的处理。已完成。    
21. 根据 CheckBox 勾选，删除勾选的这一条。已完成。    
22. 根据 CheckBox 勾选，删除勾选的多条。已完成。    
23. 刚进入网页的时候，删除用户按钮为 disabled。已完成。  
24. 如果没有勾选，删除用户按钮为 disabled；勾选以后为可点击状态。已完成。 
25. 删除用户以后，删除用户按钮为 disabled。已完成。  
26. 实现登录。已完成。  
27. 看 login 视图函数。已完成。
28. 请求 login 接口。已完成。
29. 拿到 token。已完成。
30. 把 token 添加到 headers 里。已完成。
31. 看后端哪里用到了 token。已完成。
32. token 怎么设置成全局变量。（用 localStorage）已完成。  
33. 怎么获取当前用户属性。已完成。  
34. 修改密码接口。已完成。  
35. 完善修改密码接口。已完成。  
36. 先走通修改密码接口。已完成。  
37. 根据用户，实现密码修改。已完成。  
38. 看权限接口代码。已完成。  
39. 走通数据库。已完成。
40. 弄懂 type 是什么，怎么传。已完成。  
41. 走通 permission list 接口。已完成。
42. 根据当前用户的权限，判断左侧哪些内容显示，哪些内容隐藏。已完成。  
43. 通过 jQuery 实现左侧显示？  
44. 实现管理员和研究人员登录按钮。已完成。    
45. 根据用户，在右上角显示不同的用户名。通过视图函数实现。已完成。  
46. 弄清楚链接跳转的流程。已完成。
47. 弄清楚 cookie 和 localStorage 的作用。已完成。  
48. 完成跳转。已完成。  



# 热词统计 01.13  
1. 读 Excel。已完成。  
2. 两列，去空白符。已完成。  
3. 逗号分词。已完成。  
4. 正则匹配。已完成。  
5. 统计词频。已完成。  
6. 循环 update。已完成。  
7. 同义词相加。已完成。  
8. 取最高值。已完成。  



# 专家观点库姓名识别基本功能 01.06  

1. 去治理索引找一篇文章，有人名，有全称。已完成。  
3. 动词匹配。用正则表达式，findall 和 finditer。已完成。  
4. 判断有没有分段。str.find("\n") 或 re.findall("\n") 或者 re.finditer("\n")。已完成。  
5. 如果分段，就在一个段落里找，如果没有分段，就在一句话里找。怎么判断一句话。已完成。  
6. 往前找和往后找。已完成。  
7. 跑词性。已完成。  
8. 找全称的正则。已完成。 
9. 找 PER。已完成。   
10. 把结果合成一个列表。已完成。  
11. 列表排序。已完成。  
12. 实现 name_map。已完成。  
13. 根据姓名相对于动词的位置，进行排序。已完成。    
14. 根据 type，判断是否返回。已完成。  


# 训练模型 01.03    

一、先训练多句模型  
1. 看交叉验证  
2. 准备训练集  
3. 训练模型  
4. 交叉验证  



1. 复制代码。已完成。 
2. 读代码，看用到了哪些函数。已完成。 
3. 把用到的函数复制过去。已完成。  
4. 看调用函数有什么修改。已完成。  
5. 准备训练集。已完成。  
6. 执行一下过程，看看报什么错，进行相应的调整，看看生成的数据的格式  
7. 写 shell 脚本  
8. 完成 predict  


# 重新训练一版多句模型  12.26 

1. 先删除训练的模型。已完成。  
2. 找到 c 和 d 数据。已完成。  
3. 处理第二次标注的 c 和 d 类型的数据，先分组  
4. 根据规则合并 
5. 准备多句模型数据  
6. 多句模型数据标签替换  
7. 合并单句数据  



# 海上装备后台 12.15  

1. 先布局。已完成。  
2. 先创建出一个空页面出来。已完成。    
3. 添加表格。已完成。    
4. 添加管理员三角形。已完成。  
5. 实现弹框。已完成。    
6. 复制粘贴，创建多个页面。已完成。  



# 用第二次标注数据迭代模型 12.11  

1. 上传第二次标注数据。已完成  
2. 找到原始 3 万条单句样本。已完成。train_trainv6_norm.json  
3. 把原始单句样本中的第二次标注的数据的标签，替换为重新标注的标签。已完成。  
4. 合并单句样本和第一次标注的 5000 条样本。已完成。合并以后的数据为 work/v11/train_trainv11_norm.json   
5. 训练模型。已完成。  
6. 找到测试集。已完成。    
7. 测试效果。已完成。  


# 第 2 个单句模型 12.09 

1. 找到重新标注的 5000 条。已完成。是 work/v10/cd_relabel.json  
2. 找到单句样本。已完成。是 clue_classifier/CLUEdatasets/semeval_trainv6/train_trainv6_norm.json  
3. 取第 2 个 5000 条。已完成。  
4. 合并 json 文件，生成训练集。已完成。  
5. 训练模型。已完成。   
6. 准备好测试集。已完成。work/v10/train_trainv6_norm_first_5000.json    
7. 预测结果。已完成。    
8. 用 cleanlab 统计错例。已完成。  



# 单句训练 12.09   

1. 找到标注以后的数据。已完成。在 work/v10/模型反馈样本数据-标注后.xlsx    
2. 转换成 JSON 文件。已完成。重新标注以后的数据在 work/v10/cd_relabel.json  
3. 用标注以后的数据训练一个模型。已完成。
4. 用这个模型在单句样本上测试效果。已完成。  



# 迭代单句模型 12.01 

测试结果  

准备测试数据：  
1. 找到原始数据 290000 样本。已完成。是 work/v8/final_trainv8_norm_290000.json    
2. 找到 c 和 d 类型的数据。已完成。是 work/v8/c_label0_some_preds1.json 和 work/v8/d_label1_all_preds0.json  
3. 把 c 和 d 从原始数据中去除。已完成。  
4. 在去掉 c 和 d 后剩下的数据中随机采样，取一半。已完成。  
5. 找到训练集。已完成。  
6. 在 c 和 d 中去掉重新标注的训练集。已完成。    
7. 把 c 和 d 中剩下的数据拼接到随机采样一半的结果里。已完成。测试集是：half_sample_test_set_with_cd.json    
8. 先用原来的模型在测试集上测试效果  
9. 再用迭代的模型在测试集上测试效果  



# 添加 url、原来的评级和模型预测标签 11.26  

1. 先做预测标签，查生成的 Excel，复制、替换。已完成。  
2. url 和原来的评级一起做，读原始数据，处理成字典格式进行遍历。


# 文本转为 Excel 格式 11.21  

1. 取 10 条做实验。复制粘贴就可以。已完成。  
2. 写入 Excel。已完成。  
3. 写入多个 sheet。已完成。  
4. 写入 Excel 按句子 split。已完成。  
5. 颜色高亮。已完成。    


# 测 LAC 分词速度 11.17   

## 方法 1 

1. 读 CSV 文件  
2. 过 LAC  
3. 打标签  


# 皮卡专家观点提取 11.17    

## 方法 1 

1. 先从 es 取数据  
2. 用动词过滤  
3. 用正则过滤  
4. title 去重  


# 单句模型处理测试集 11.16  

## 方法 1   

`label_map = {1: "负面", 0: "正面"}`  

1. 怎么遍历多句
2. 怎么把句子送进模型
3. 怎么决定输出


## 方法 2 

1. 遍历多句 
2. 返回句子个数列表  
3. 跑模型，得到中间每个句子的结果
4. 根据结果分组，根据分组得到最后的结果


# 具体内容错例分析 11.11 

## 方法 1 

错例和句子个数的相关性  

1. 把正确的例子从验证集中分出来。已完成。  
2. 统计错例句子长度各自占比。 
3. 统计正确句子长度各自占比  
4. 比较结果  


# 错例分析 11.10   

## 方法 1 

1. predict 验证集  
2. 拿到 test_prediction.json  
3. 把 test_prediction 标签和验证集标签做对比，直接用 zip 就可以    
4. 不相等的拿出来  
5. 分析  



# ES 改 flag 脚本 11.09 

## 方法 1  

1. 先取数据
2. 拿到 flag 字段 
3. 做判断  
4. update 字段  


# 国家统计和国家文章列表缓存没有生效  11.04 

## 方法 1   

1. 看 Redis 里有没有缓存  
2. 看代码中是在哪里取的缓存  
3. 有没有取到缓存？为什么  

先确认国家统计是不是每次请求。已完成，是每次都重新请求。    

确认国家统计有没有生效。缓存没有生效。    

然后看文章列表。没有问题。    


# 训练 en v3 模型 11.03  

换数据执行命令应该就行了  

1. 先删除原来的模型。已完成。  
2. 换数据。已完成。    
3. 改标签。已完成。  
4. 训练新的模型。已完成。
5. 模型部署。已完成。  
6. 跑数据。已完成。    


已完成。  

改脚本，说清楚原来的问题，怎么改  

走通原来的代码  
说清楚原来的问题  
给出解决方案  


# 字幕和花字分离 11.01   

## 方法 4   

有两个问题：  
1. 字幕顺序被打乱了；先确定是不是乱了，对比视频和文字。已完成，确定顺序是乱的；乱了怎么排序；用 pandas 的 sort_values()    
2. 按照高度限制。1、高度是多少？2、限制写在哪里？3、怎么设置为空  


## 方法 3 

两条路  

1、读代码，理解思想 
2、再找别的项目  


## 方法 2   

先读 readme 文档。已完成。    

走通流程  

debug 5 遍代码  


## 方法 1  

### 问题  

识别的字不一样  
重复率取多少？文本长短，比如一共 10 句话，一句字幕就占了 10%。可能还要做判断。  
怎么根据位置判断。（每个视频字幕位置不一样）  


### 流程  

2. 定规则  
① 不管技术，定规则  
字幕相对固定，出现在特定区域，并且持续出现，内容变化度高  
花字重复率高，每帧识别结果重复度高  

② 考虑技术
先判断重复率，重复率非常高的是花字  
再判断位置，位置相对固定的，内容变化度高的是字幕  

7. 根据位置和变化率进行判断  


### 已完成  

1. 读聊天记录，读文档，读 CSV 文件，读脚本。完成   

2. 读取 CSV 文本。已完成。  

3. 统计数量。已完成。

4. 算重复率。已完成。  

5. 提取位置  
坐标含义：已完成。  


# 预测治理统计匹配的每一步都是多少数据 10.26  

## 方法 1  

先做预测，先做中文    


### 分析过程  

1. 姓名匹配以后剩多少？姓名匹配是在哪里做的。  
先看视图函数和 middleware，先看预测  
4. 正则怎么匹配  


### 已解决  

中文预测  
1. 处理之前：22811145 条  
2. 匹配完动词：7353923 条   
3. 匹配完标志词：736329 条  
4. 过完模型：18140 条  
5. 姓名匹配：10706 条  


中文治理  
1. 处理之前：22811145 条   
2. 匹配完动词：7353923 条   
3. 匹配完标志词：    
4. 过完模型：193758 条   
5. 姓名匹配：128718 条  


英文预测  
1. 处理之前：194309 条   
2. 匹配完标志词：26387 条  
3. 过完模型：2483 条  


英文治理  
1. 处理之前：194309 条  
2. 匹配完标志词：84333 条  
3. 过完模型：18226 条   


# 技术预测和技术治理的提取 09.07   

先做技术治理。  

原来是在全文里找，现在要在一段里找。  

1、原来是怎么找的。  
2、这一段是怎么找的。  
3、把全文改成一段就可以了。  

有一个问题是，现在的技术预测里的 point_text 有些是全文。这个最后做。  



不是看预测和治理，而是看专家观点。  


技术治理原来显示的内容是怎么找的。  

原来是直接用的 zhili_text，在 es 里就是有 zhili_text。  

es 索引是 zhili-zky，有 zhili_text 这个字段，看这个字段是怎么上传到 es 中去的  

找不到。  



看一看预测原来显示的内容是怎么找的。  


08.23  

# 只显示 10 页，10 页以后的内容没有办法显示

问题产生的原因：最开始返回的总页数是，从 ES 里查的总数，但是使用缓存的时候就改成了单批缓存的数量。  

解决办法：使用缓存的时候，不要使用单批缓存的数量，而是使用总数量的缓存。  


# 判断是使用缓存，还是再次请求

最开始是想使用页数，想在缓存名前加页数，一直不成功，点击 15 页，没有文章显示，而且会报错，说是无效的请求。  

这个问题的核心是判断当前数量是在缓存范围内，还是缓存范围之外；如果是在缓存范围之内，就使用缓存，如果在缓存范围之外，就再次去 ES 里查询

解决办法：用数量做判断。如果在数量以内，就使用缓存，如果在数量以外，就再次取 ES 里查询。    



